{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "# was running numpy version 1.19.2 which isn't compatible w/ tensorflow\n",
    "# force to run updated version of numpy\n",
    "pkg_resources.require(\"numpy==1.22.2\")  \n",
    "import numpy as np\n",
    "\n",
    "# libraries for data cleaning and preparation for model\n",
    "import os\n",
    "import os.path\n",
    "import chess\n",
    "import chess.pgn\n",
    "\n",
    "# libraries for GAN model\n",
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D,Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation,Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# libraries for visuals\n",
    "import matplotlib.pyplot as mpl\n",
    "import pydot\n",
    "import pydotplus\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractdata(pgn_path):\n",
    "    '''\n",
    "    input: pgn files of player\n",
    "    output: \n",
    "        function returns step-by-step gameplay as a list\n",
    "        function returns which player is playing White as a list\n",
    "    \n",
    "    list 'side' will be used to ensure only moves made by \n",
    "    intended player will be used in creation of the GAN\n",
    "    '''\n",
    "    \n",
    "    pgn = open(pgn_path, encoding='utf-8')\n",
    "    \n",
    "    side = []\n",
    "    game_moves = []\n",
    "    while True:\n",
    "        try:\n",
    "            this_game = chess.pgn.read_game(pgn)\n",
    "            game_moves.append(this_game.mainline_moves()) \n",
    "            side.append(this_game.headers[\"White\"]) \n",
    "        except:\n",
    "            break\n",
    "\n",
    "    return game_moves, side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_moves(game_moves, side, name):\n",
    "    '''\n",
    "    input: game_moves and side list from extractdata function\n",
    "    output:\n",
    "        function returns 2 lists, which contain all of player's move\n",
    "        list PW: player's moves when they are playing white\n",
    "        list PB: player's moves when they are playing black \n",
    "    '''\n",
    "    \n",
    "    PW = [] # empty list for all moves when player playing white\n",
    "    PB = [] # empty list for all moves when player playing black\n",
    "    \n",
    "    match = 0\n",
    "    \n",
    "    for game in game_moves:\n",
    "        board = chess.Board() # saves FEN notation of chess board\n",
    "        white = side[match]\n",
    "        count = 0\n",
    "        \n",
    "        if name in white:\n",
    "            index = 1\n",
    "            for move in game:\n",
    "                if index % 2 == 0:\n",
    "                    PW.append(board.copy()) # creates list PW of moves when the player is playing white\n",
    "                board.push(move) # move game forward one move\n",
    "                index = index + 1\n",
    "                \n",
    "    \n",
    "        if name not in white:\n",
    "            index = 0\n",
    "            for move in game:\n",
    "                board.push(move)\n",
    "                \n",
    "                if index % 2 == 1:\n",
    "                    PB.append(board.copy()) # creates list PB of moves when the player is playing black\n",
    "                index = index + 1\n",
    "        \n",
    "        match = match + 1\n",
    "       \n",
    "    return PW, PB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(board): \n",
    "    '''\n",
    "    input: FEN notation of a board position\n",
    "    output: matrix representing board position at a given moment\n",
    "        each board square is an individual item in the matrix, blank squares are represented by a period\n",
    "    '''\n",
    "    \n",
    "    pgn = board.epd() # convert FEN notation of board into EPD notation\n",
    "    matrix = []  \n",
    "\n",
    "    # retrieve only the first field from EPD notation: the piece placement\n",
    "    pieces = pgn.split(\" \", 1)[0] \n",
    "    \n",
    "    # separate into placement of individual pieces\n",
    "    rows = pieces.split(\"/\")\n",
    "    \n",
    "    # separates rows so that each specific square on the board is its own list entry, formatted as a matrix\n",
    "    for row in rows:\n",
    "        game_row = []  \n",
    "        for item in row:\n",
    "            if item.isdigit():\n",
    "            \n",
    "            # replaces numbers in epd that represent the number of empty squares with a period for each empty square\n",
    "            # example: '8' = '........'\n",
    "            \n",
    "                for i in range(0, int(item)):\n",
    "                    game_row.append('.')\n",
    "            else:\n",
    "                game_row.append(item)\n",
    "        matrix.append(game_row)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate game pieces to binary values using one-hot encoding\n",
    "# each game piece is represented by a unique binary vector\n",
    "\n",
    "chess_dict = {\n",
    "    'p' : [1,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'P' : [0,0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "    'n' : [0,1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    'N' : [0,0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "    'b' : [0,0,1,0,0,0,0,0,0,0,0,0,0],\n",
    "    'B' : [0,0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "    'r' : [0,0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "    'R' : [0,0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "    'q' : [0,0,0,0,1,0,0,0,0,0,0,0,0],\n",
    "    'Q' : [0,0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "    'k' : [0,0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "    'K' : [0,0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "    '.' : [0,0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(matrix, chess_dict):\n",
    "    '''\n",
    "    input: matrix created in the previous function, chess dictionary\n",
    "    output: layout of a chess board represented by a matrix of one-hot encoded values\n",
    "    '''\n",
    "    \n",
    "    rows = []\n",
    "    for row in matrix:\n",
    "        pieces = []\n",
    "        for piece in row:\n",
    "\n",
    "            # appends one-hot endoded value associated with each chess piece, pulled from chess_dict\n",
    "            pieces.append(chess_dict[piece])\n",
    "        rows.append(pieces)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_matrix(X, Y):\n",
    "    '''\n",
    "    inputs:\n",
    "        X: list of moves when player is playing white\n",
    "        Y: list of moves when player is playing black\n",
    "        \n",
    "    translate and make_matrix functions to convert each instance of the game board into a one-hot encoded matrix\n",
    "    then transforms matrix into numpy array\n",
    "    \n",
    "    outputs:\n",
    "        X_array: numpy array of all moves when player is playing white\n",
    "        Y_array: numpy array of all moves when player is playing black\n",
    "    '''\n",
    "    for i in range(len(X)):\n",
    "        X[i] = translate(make_matrix(X[i]),chess_dict)\n",
    "    for i in range(len(Y)):\n",
    "        Y[i] = translate(make_matrix(Y[i]),chess_dict)\n",
    "    X_array = np.array(X)\n",
    "    Y_array = np.array(Y)\n",
    "\n",
    "    return X_array, Y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(image_shape = (8,8,13)):\n",
    "    '''\n",
    "    create the PatchGAN discriminator model\n",
    "    \n",
    "    model takes a chess move from the source domain (real move) and a chess move from the target domain \n",
    "    (imitated move) and predicts the likelihood (known as the error) of whether the move from the target \n",
    "    domain is a real or generated version of the chess player's gameplay\n",
    "    '''\n",
    "    \n",
    "    # initiatlize as randomly distributed with a SD of 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # real chess move input\n",
    "    in_src_image = Input(shape=image_shape)\n",
    "    \n",
    "    # imitated chess move input\n",
    "    in_target_image = Input(shape=image_shape)\n",
    "\n",
    "    # concatenate images channel-wise\n",
    "    # create one 256x256x6 input to the first hidden convolutional layer\n",
    "    merged = concatenate([in_src_image, in_target_image])\n",
    "    \n",
    "    # C64\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C128\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    \n",
    "    #normalizes output using moving average of mean and standard deviation of the batches it has seen during training.\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C256\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # C512\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    \n",
    "    # second to last output layer\n",
    "    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\n",
    "    # patch output\n",
    "    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    \n",
    "    # define model\n",
    "    model = Model(inputs = [in_src_image, in_target_image], outputs = patch_out)\n",
    "\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "    '''\n",
    "    this function defines the encoder block of the final generator function\n",
    "    \n",
    "    inputs: \n",
    "        current layer of model (layer_in), number of filters (n_filters), presence or absence of batch normalization\n",
    "        \n",
    "    output: encoded layer\n",
    "    '''\n",
    "    # initiatlize as randomly distributed with a SD of 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "   \n",
    "    # add downsampling layer\n",
    "    # flattes given image to a 2D structure\n",
    "    # convolutional layers that use a 2×2 stride to downsample the input source image down to a bottleneck layer\n",
    "    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    \n",
    "    # conditionally add batch normalization\n",
    "    # normalizes its output using the mean and standard deviation of the current batch of inputs\n",
    "    if batchnorm:\n",
    "        g = BatchNormalization()(g, training=True)\n",
    "    \n",
    "    # leaky relu activation\n",
    "    # more balanced than regular relu, may learn faster\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "    '''\n",
    "    this function defines the decoder block of the final generator function\n",
    "    uses transpose convolutional layers to upsample to required output image size\n",
    "    \n",
    "    inputs: \n",
    "        current layer of model, encoded (layer_in), \n",
    "        skip connection input (skip_in), number of filters (n_filters), \n",
    "        introduction of dropout layers as a source of randomness\n",
    "    \n",
    "    output: decoded layer\n",
    "    '''\n",
    "\n",
    "    # initiatlize as randomly distributed with a SD of 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    \n",
    "    # add unsampling layer\n",
    "    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    \n",
    "    # add batch normalization\n",
    "    # normalizes its output using the mean and standard deviation of the current batch of inputs\n",
    "    g = BatchNormalization()(g, training=True)\n",
    "    \n",
    "    # conditionally add dropout\n",
    "    if dropout:\n",
    "        g = Dropout(0.5)(g, training=True)\n",
    "    \n",
    "    # merge with skip connection\n",
    "    g = concatenate([g, skip_in])\n",
    "    # relu activation\n",
    "    g = Activation('relu')(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(image_shape=(8,8,13)):\n",
    "    '''\n",
    "    function defines standalone generator model\n",
    "\n",
    "    inputs: image_shape, for chess board it is 8 x 8 x 13\n",
    "        8 x 8 represents size of the board, 13 represents depth, or number of possible pieces that could\n",
    "        fill each chess board square, as defined above in chess_dict\n",
    "        \n",
    "    output: standalone generator model that creates chess gameplay moves that attempt to imitate the player\n",
    "    and 'trick' the discriminator into believing it is a real move by that player\n",
    "    '''\n",
    "\n",
    "    # initiatlize as randomly distributed with a SD of 0.02\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    # image input\n",
    "    in_image = Input(shape=image_shape)\n",
    "\n",
    "    # encoder model\n",
    "    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "    e2 = define_encoder_block(e1, 128)\n",
    "    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e2)\n",
    "    b = Activation('relu')(b)\n",
    "    \n",
    "    # decoder model\n",
    "    d6 = define_decoder_block(b, e2, 128, dropout=False)\n",
    "    d7 = define_decoder_block(d6, e1, 64, dropout=False)\n",
    "    g = Conv2DTranspose(13, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "\n",
    "    # 'softmax' converts a vector of values to a probability distribution\n",
    "    out_image = Activation('softmax')(g)\n",
    "\n",
    "    # define generator model itself\n",
    "    model = Model(in_image, out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model, image_shape):\n",
    "    '''\n",
    "    function defined the final GAN model\n",
    "    inputs: generator model, discriminator model, shape of image to be generated \n",
    "        shape will be 8x8x13 to represent possible positions on a chess board\n",
    "        \n",
    "    output: usable GAN model\n",
    "    '''\n",
    "    d_model.trainable = False\n",
    "    # define source image\n",
    "    in_src = Input(shape=image_shape)\n",
    "    # connect source input to the generator input\n",
    "    gen_out = g_model(in_src)\n",
    "    # connect source input and generator output to the discriminator input\n",
    "    dis_out = d_model([in_src, gen_out])\n",
    "    \n",
    "    # source image as input, generated image and classification (real/fake) as output\n",
    "    model = Model(in_src, [dis_out, gen_out])\n",
    "\n",
    "    # compile final model with Adam optimizer\n",
    "    # Adam optimizer:\n",
    "        # computationally efficient, doesn't require a lot of memory, maintains single learning rate\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "    '''\n",
    "    function pulls real samples of chess moves from the dataset\n",
    "    \n",
    "    inputs: pgn file of players moves (dataset), number of samples to create (n_samples),\n",
    "    shape of discriminator model output (patch_shape)\n",
    "    \n",
    "    outputs: real chess move data\n",
    "    '''\n",
    "    trainA, trainB = dataset\n",
    "    # choose random chess moves from dataset\n",
    "    ix_x = randint(0, trainA.shape[0], n_samples)\n",
    "    ix_y = randint(0, trainB.shape[0], n_samples)\n",
    "    \n",
    "    # selects lower of two random indices to ensure that each dataset has an observation at that point\n",
    "    if ix_x <= ix_y:\n",
    "        ix = ix_x\n",
    "    else:\n",
    "        ix = ix_y\n",
    "    \n",
    "    X1, X2 = trainA[ix], trainB[ix]\n",
    "    # labels them with '1' to designate that they are real\n",
    "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "    '''\n",
    "    function creates fake samples of chess moves using the generator model\n",
    "    \n",
    "    inputs: generator model (g_model), real samples from dataset (samples), \n",
    "    and shape of discriminator model output (patch_shape)\n",
    "    \n",
    "    outputs: fake samples of chess moves\n",
    "    '''\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    # labels them with '0' to designate that they are real\n",
    "    y = zeros((len(X), patch_shape, patch_shape, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model, dataset, n_epochs=1, n_batch=1):\n",
    "    '''\n",
    "    function trains the model to imitate the chess player\n",
    "    \n",
    "    inputs: disrimiantor model, generator model, combined GAN model, data to be used\n",
    "    '''\n",
    "    n_patch = d_model.output_shape[1]\n",
    "    trainA, trainB = dataset\n",
    "    bat_per_epo = int(len(trainA) / n_batch)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    d_loss1_list = []\n",
    "    d_loss2_list = []\n",
    "    g_loss_list = []\n",
    "    steps = []\n",
    "    \n",
    "    for i in range(n_steps):\n",
    "        [X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    "        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        d_loss1_list.append(d_loss1)\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        d_loss2_list.append(d_loss2)\n",
    "        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "        g_loss_list.append(g_loss)\n",
    "        steps.append(i)        \n",
    "        # use during training to see step-by-step loss values\n",
    "        #print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "    if (i+1) % (bat_per_epo * 10) == 0:\n",
    "        clear_output()\n",
    "    return d_loss1_list, d_loss2_list, g_loss_list, steps, gan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "alekhine = \"/Users/zoepratt/Documents/GitHub/Top-Chess-Players/code/alekhine.pgn\"\n",
    "anand = \"/Users/zoepratt/Documents/GitHub/Top-Chess-Players/code/anand.pgn\"\n",
    "carlsen = \"/Users/zoepratt/Documents/GitHub/Top-Chess-Players/code/carlsen.pgn\"\n",
    "caruana = \"/Users/zoepratt/Documents/GitHub/Top-Chess-Players/code/caruana.pgn\"\n",
    "kasparov = \"/Users/zoepratt/Documents/GitHub/Top-Chess-Players/code/kasparov.pgn\"\n",
    "nakamura = \"/Users/zoepratt/Documents/GitHub/Top-Chess-Players/code/nakamura.pgn\"\n",
    "polgar = \"/Users/zoepratt/Documents/GitHub/Top-Chess-Players/code/polgar.pgn\"\n",
    "tal = \"/Users/zoepratt/Documents/GitHub/Top-Chess-Players/code/tal.pgn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alekhine GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_moves, side = extractdata(alekhine)\n",
    "PW, PB = categorize_moves(game_moves, side, 'Alekhine')\n",
    "X, y = one_hot_matrix(PW, PB)\n",
    "d_model = define_discriminator(image_shape = (8,8,13))\n",
    "g_model = define_generator()\n",
    "gan_model = define_gan(g_model, d_model, image_shape = (8,8,13))\n",
    "d_loss1_list, d_loss2_list, g_loss_list, steps, gan_model = train(d_model, g_model, gan_model, [X, y])\n",
    "gan_model.save('alekhine.h5') # save model to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpl.plot(steps, g_loss_list)\n",
    "mpl.xlabel(\"Training Iteration\")\n",
    "mpl.ylabel(\"Generator Loss\")\n",
    "mpl.title('Alekhine GAN performance')\n",
    "mpl.text(0,g_loss_list[0],round(g_loss_list[0], 2))\n",
    "mpl.text(steps[-1],g_loss_list[-1],round(g_loss_list[-1], 2))\n",
    "mpl.savefig('alekhineGAN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alekhine_d = plot_model(d_model, to_file='alekhine_d_model.png', show_shapes=True, show_layer_names=True)\n",
    "alekhine_g = plot_model(g_model, to_file='alekhine_g_model.png', show_shapes=True, show_layer_names=True)\n",
    "alekhine_gan = plot_model(gan_model, to_file='alekhine_gan_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ALEKHINE DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Anand GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_moves, side = extractdata(anand)\n",
    "PW, PB = categorize_moves(game_moves, side, 'Anand')\n",
    "X, y = one_hot_matrix(PW, PB)\n",
    "d_model = define_discriminator(image_shape = (8,8,13))\n",
    "g_model = define_generator()\n",
    "gan_model = define_gan(g_model, d_model, image_shape = (8,8,13))\n",
    "d_loss1_list, d_loss2_list, g_loss_list, steps, gan_model = train(d_model, g_model, gan_model, [X, y])\n",
    "gan_model.save('anand.h5') # save model to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.plot(steps, g_loss_list)\n",
    "mpl.xlabel(\"Training Iteration\")\n",
    "mpl.ylabel(\"Generator Loss\")\n",
    "mpl.title('Anand GAN performance')\n",
    "mpl.text(0,g_loss_list[0],round(g_loss_list[0], 2))\n",
    "mpl.text(steps[-1],g_loss_list[-1],round(g_loss_list[-1], 2))\n",
    "mpl.savefig('anandGAN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anand_d = plot_model(d_model, to_file='anand_d_model.png', show_shapes=True, show_layer_names=True)\n",
    "anand_g = plot_model(g_model, to_file='anand_g_model.png', show_shapes=True, show_layer_names=True)\n",
    "anand_gan = plot_model(gan_model, to_file='anand_gan_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ANAND DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carlsen GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_moves, side = extractdata(carlsen)\n",
    "PW, PB = categorize_moves(game_moves, side, 'Carlsen')\n",
    "X, y = one_hot_matrix(PW, PB)\n",
    "d_model = define_discriminator(image_shape = (8,8,13))\n",
    "g_model = define_generator()\n",
    "gan_model = define_gan(g_model, d_model, image_shape = (8,8,13))\n",
    "d_loss1_list, d_loss2_list, g_loss_list, steps, gan_model = train(d_model, g_model, gan_model, [X, y])\n",
    "gan_model.save('carlsen.h5') # save model to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.plot(steps, g_loss_list)\n",
    "mpl.xlabel(\"Training Iteration\")\n",
    "mpl.ylabel(\"Generator Loss\")\n",
    "mpl.title('Carlsen GAN performance')\n",
    "mpl.text(0,g_loss_list[0],round(g_loss_list[0], 2))\n",
    "mpl.text(steps[-1],g_loss_list[-1],round(g_loss_list[-1], 2))\n",
    "mpl.savefig('carlsenGAN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carlsen_d = plot_model(d_model, to_file='carlsen_d_model.png', show_shapes=True, show_layer_names=True)\n",
    "carlsen_g = plot_model(g_model, to_file='carlsen_g_model.png', show_shapes=True, show_layer_names=True)\n",
    "carlsen_gan = plot_model(gan_model, to_file='carlsen_gan_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CARLSEN DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caruana GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_moves, side = extractdata(caruana)\n",
    "PW, PB = categorize_moves(game_moves, side, 'Caruana')\n",
    "X, y = one_hot_matrix(PW, PB)\n",
    "d_model = define_discriminator(image_shape = (8,8,13))\n",
    "g_model = define_generator()\n",
    "gan_model = define_gan(g_model, d_model, image_shape = (8,8,13))\n",
    "d_loss1_list, d_loss2_list, g_loss_list, steps, gan_model = train(d_model, g_model, gan_model, [X, y])\n",
    "gan_model.save('caruana.h5') # save model to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.plot(steps, g_loss_list)\n",
    "mpl.xlabel(\"Training Iteration\")\n",
    "mpl.ylabel(\"Generator Loss\")\n",
    "mpl.title('Caruana GAN performance')\n",
    "mpl.text(0,g_loss_list[0],round(g_loss_list[0], 2))\n",
    "mpl.text(steps[-1],g_loss_list[-1],round(g_loss_list[-1], 2))\n",
    "mpl.savefig('caruanaGAN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caruana_d = plot_model(d_model, to_file='caruana_d_model.png', show_shapes=True, show_layer_names=True)\n",
    "caruana_g = plot_model(g_model, to_file='caruana_g_model.png', show_shapes=True, show_layer_names=True)\n",
    "caruana_gan = plot_model(gan_model, to_file='caruana_gan_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CARUANA DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kasparov GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_moves, side = extractdata(kasparov)\n",
    "PW, PB = categorize_moves(game_moves, side, 'Kasparov')\n",
    "X, y = one_hot_matrix(PW, PB)\n",
    "d_model = define_discriminator(image_shape = (8,8,13))\n",
    "g_model = define_generator()\n",
    "gan_model = define_gan(g_model, d_model, image_shape = (8,8,13))\n",
    "d_loss1_list, d_loss2_list, g_loss_list, steps, gan_model = train(d_model, g_model, gan_model, [X, y])\n",
    "gan_model.save('kasparov.h5') # save model to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.plot(steps, g_loss_list)\n",
    "mpl.xlabel(\"Training Iteration\")\n",
    "mpl.ylabel(\"Generator Loss\")\n",
    "mpl.title('Kasparov GAN performance')\n",
    "mpl.text(0,g_loss_list[0],round(g_loss_list[0], 2))\n",
    "mpl.text(steps[-1],g_loss_list[-1],round(g_loss_list[-1], 2))\n",
    "mpl.savefig('kasparovGAN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kasparov_d = plot_model(d_model, to_file='kasparov_d_model.png', show_shapes=True, show_layer_names=True)\n",
    "kasparov_g = plot_model(g_model, to_file='kasparov_g_model.png', show_shapes=True, show_layer_names=True)\n",
    "kasparov_gan = plot_model(gan_model, to_file='kasparov_gan_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KASPAROV DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nakamura GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_moves, side = extractdata(nakamura)\n",
    "PW, PB = categorize_moves(game_moves, side, 'Nakamura')\n",
    "X, y = one_hot_matrix(PW, PB)\n",
    "d_model = define_discriminator(image_shape = (8,8,13))\n",
    "g_model = define_generator()\n",
    "gan_model = define_gan(g_model, d_model, image_shape = (8,8,13))\n",
    "d_loss1_list, d_loss2_list, g_loss_list, steps, gan_model = train(d_model, g_model, gan_model, [X, y])\n",
    "gan_model.save('nakamura.h5') # save model to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.plot(steps, g_loss_list)\n",
    "mpl.xlabel(\"Training Iteration\")\n",
    "mpl.ylabel(\"Generator Loss\")\n",
    "mpl.title('Nakamura GAN performance')\n",
    "mpl.text(0,g_loss_list[0],round(g_loss_list[0], 2))\n",
    "mpl.text(steps[-1],g_loss_list[-1],round(g_loss_list[-1], 2))\n",
    "mpl.savefig('nakamuraGAN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nakamura_d = plot_model(d_model, to_file='nakamura_d_model.png', show_shapes=True, show_layer_names=True)\n",
    "nakamura_g = plot_model(g_model, to_file='nakamura_g_model.png', show_shapes=True, show_layer_names=True)\n",
    "nakamura_gan = plot_model(gan_model, to_file='nakamura_gan_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NAKAMURA DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polgar GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_moves, side = extractdata(polgar)\n",
    "PW, PB = categorize_moves(game_moves, side, 'Polgar')\n",
    "X, y = one_hot_matrix(PW, PB)\n",
    "d_model = define_discriminator(image_shape = (8,8,13))\n",
    "g_model = define_generator()\n",
    "gan_model = define_gan(g_model, d_model, image_shape = (8,8,13))\n",
    "d_loss1_list, d_loss2_list, g_loss_list, steps, gan_model = train(d_model, g_model, gan_model, [X, y])\n",
    "gan_model.save('polgar.h5') # save model to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.plot(steps, g_loss_list)\n",
    "mpl.xlabel(\"Training Iteration\")\n",
    "mpl.ylabel(\"Generator Loss\")\n",
    "mpl.title('Polgar GAN performance')\n",
    "mpl.text(0,g_loss_list[0],round(g_loss_list[0], 2))\n",
    "mpl.text(steps[-1],g_loss_list[-1],round(g_loss_list[-1], 2))\n",
    "mpl.savefig('polgarGAN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polgar_d = plot_model(d_model, to_file='polgar_d_model.png', show_shapes=True, show_layer_names=True)\n",
    "polgar_g = plot_model(g_model, to_file='polgar_g_model.png', show_shapes=True, show_layer_names=True)\n",
    "polgar_gan = plot_model(gan_model, to_file='polgar_gan_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('POLGAR DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tal GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_moves, side = extractdata(tal)\n",
    "PW, PB = categorize_moves(game_moves, side, 'Tal')\n",
    "X, y = one_hot_matrix(PW, PB)\n",
    "d_model = define_discriminator(image_shape = (8,8,13))\n",
    "g_model = define_generator()\n",
    "gan_model = define_gan(g_model, d_model, image_shape = (8,8,13))\n",
    "d_loss1_list, d_loss2_list, g_loss_list, steps, gan_model = train(d_model, g_model, gan_model, [X, y])\n",
    "gan_model.save('tal.h5') # save model to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.plot(steps, g_loss_list)\n",
    "mpl.xlabel(\"Training Iteration\")\n",
    "mpl.ylabel(\"Generator Loss\")\n",
    "mpl.title('Tal GAN performance')\n",
    "mpl.text(0,g_loss_list[0],round(g_loss_list[0], 2))\n",
    "mpl.text(steps[-1],g_loss_list[-1],round(g_loss_list[-1], 2))\n",
    "mpl.savefig('talGAN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tal_d = plot_model(d_model, to_file='tal_d_model.png', show_shapes=True, show_layer_names=True)\n",
    "tal_g = plot_model(g_model, to_file='tal_g_model.png', show_shapes=True, show_layer_names=True)\n",
    "tal_gan = plot_model(gan_model, to_file='tal_gan_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TAL DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PROGRAM COMPLETE! GANs are loaded to folder')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
